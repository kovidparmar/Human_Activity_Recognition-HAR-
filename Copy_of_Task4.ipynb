{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saharsh2k5/ML_ASSIGNMENT_1/blob/main/Copy_of_Task4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV-zhYzfjYv0",
        "outputId": "8ebe8a62-0fc9-4ff1-ce2b-6f0b16407f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWs87YruFdo-",
        "outputId": "9dca806a-1f2b-4fda-eeb6-0e6660af0de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIE9nqrpFWBe",
        "outputId": "0465c140-c0ad-43d3-e4cd-677cecc2d963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tsfel in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: ipython>=7.4.0 in /usr/local/lib/python3.10/dist-packages (from tsfel) (7.34.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (2.1.4)\n",
            "Requirement already satisfied: PyWavelets>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.7.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from tsfel) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from tsfel) (1.13.1)\n",
            "Requirement already satisfied: setuptools>=47.1.1 in /usr/local/lib/python3.10/dist-packages (from tsfel) (71.0.4)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from tsfel) (0.14.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.4.0->tsfel) (4.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->tsfel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->tsfel) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->tsfel) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->tsfel) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->tsfel) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->tsfel) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->tsfel) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->tsfel) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->tsfel) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.0->tsfel) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.0->tsfel) (24.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.4.0->tsfel) (0.8.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.12.0->tsfel) (1.16.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.4.0->tsfel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.4.0->tsfel) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "pip install tsfel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYTNu1tuEHIT"
      },
      "source": [
        "1) Use the Decision Tree model trained on the UCI-HAR dataset to predict the activities that you performed. Report the accuracy, precision, recall and confusion matrix of the model. You have three version of UCI dataset you can use a)Raw data from accelerometer, b)TSFEL featurised data, c)Features provided by author. Choose which version to use, ensuring that your test data is similar to your training data. How did the model perform? [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpq6vV_WklDs",
        "outputId": "a4008982-bc13-4f95-ff11-7352352fc560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.10.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.2.35)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (0.1.106)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_groq) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTydStXIEVfx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tsfel\n",
        "import random\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "from langchain_groq.chat_models import ChatGroq\n",
        "from sklearn.utils import shuffle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "activity_dirs_train = {\n",
        "    'LAYING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/LAYING\",\n",
        "    'SITTING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/SITTING\",\n",
        "    'STANDING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/STANDING\",\n",
        "    'WALKING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING\",\n",
        "    'WALKING_DOWNSTAIRS': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING_DOWNSTAIRS\",\n",
        "    'WALKING_UPSTAIRS': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING_UPSTAIRS\"\n",
        "}\n",
        "\n",
        "activity_dirs_test = {\n",
        "    'LAYING': \"/content/drive/MyDrive/ACTIVITIES/LAYING\",\n",
        "    'SITTING': \"/content/drive/MyDrive/ACTIVITIES/SITTING\",\n",
        "    'STANDING': \"/content/drive/MyDrive/ACTIVITIES/STANDING\",\n",
        "    'WALKING': \"/content/drive/MyDrive/ACTIVITIES/WALKING\",\n",
        "    'WALKING_DOWNSTAIRS': \"/content/drive/MyDrive/ACTIVITIES/WALKING_DOWNSTAIRS\",\n",
        "    'WALKING_UPSTAIRS': \"/content/drive/MyDrive/ACTIVITIES/WALKING_UPSTAIRS\"\n",
        "}\n",
        "\n",
        "def eval(y_test, y_pred):\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='weighted')\n",
        "  recall = recall_score(y_test, y_pred, average='weighted')\n",
        "  conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  print(\"Accuracy=\", accuracy)\n",
        "  print(f\"Precision: \",precision)\n",
        "  print(f\"Recall: \",recall)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(conf_matrix)\n",
        "\n",
        "model_name = \"llama3-70b\"\n",
        "groq_models = {\n",
        "    \"llama3-70b\": \"llama3-70b-8192\",\n",
        "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
        "    \"gemma-7b\": \"gemma-7b-it\",\n",
        "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
        "    \"llama3-8b\": \"llama3-8b-8192\",\n",
        "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
        "    \"gemma-9b\": \"gemma2-9b-it\"\n",
        "}\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/key.json') as config_file:\n",
        "    config = json.load(config_file)\n",
        "    Groq_Token = config['groq_token']\n",
        "\n",
        "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rln9n_8kD8bw",
        "outputId": "0b2764ac-4b8f-4fdd-c236-a575a973f44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy= 0.2916666666666667\n",
            "Precision:  0.10555555555555556\n",
            "Recall:  0.2916666666666667\n",
            "Confusion Matrix:\n",
            "[[0 4 0 0 0 0]\n",
            " [1 3 0 0 0 0]\n",
            " [0 3 0 1 0 0]\n",
            " [0 0 0 0 4 0]\n",
            " [0 0 0 0 4 0]\n",
            " [0 0 0 0 4 0]]\n"
          ]
        }
      ],
      "source": [
        "all_a_tot = []\n",
        "labels_train = []\n",
        "\n",
        "for activity, activity_dir in activity_dirs_train.items():\n",
        "    file_names = os.listdir(activity_dir)\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(activity_dir, file_name)\n",
        "        data = pd.read_csv(file_path, skiprows=range(1, 500), nrows=500)\n",
        "        data['a_tot'] = (data['accx']**2 + data['accy']**2 + data['accz']**2)**0.5\n",
        "        all_a_tot.extend(data['a_tot'].values)\n",
        "        labels_train.extend([activity] * len(data['a_tot']))\n",
        "\n",
        "all_a_tot = np.array(all_a_tot).reshape(-1, 1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(all_a_tot)\n",
        "\n",
        "features_list_train = []\n",
        "labels_train_final = []\n",
        "\n",
        "for activity, activity_dir in activity_dirs_train.items():\n",
        "    file_names = os.listdir(activity_dir)\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(activity_dir, file_name)\n",
        "        data = pd.read_csv(file_path, skiprows=range(1, 200), nrows=500)\n",
        "        data['a_tot'] = (data['accx']**2 + data['accy']**2 + data['accz']**2)**0.5\n",
        "        data['a_tot'] = scaler.transform(data['a_tot'].values.reshape(-1, 1))\n",
        "\n",
        "        cfg = tsfel.get_features_by_domain()\n",
        "        features = tsfel.time_series_features_extractor(cfg, data['a_tot'], verbose=0)\n",
        "\n",
        "        features_list_train.append(features.values.flatten())\n",
        "        labels_train_final.append(activity)\n",
        "\n",
        "X_train = np.array(features_list_train)\n",
        "y_train = np.array(labels_train_final)\n",
        "\n",
        "features_list_test = []\n",
        "labels_test = []\n",
        "\n",
        "for activity, activity_dir in activity_dirs_test.items():\n",
        "    file_names = os.listdir(activity_dir)\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(activity_dir, file_name)\n",
        "        data = pd.read_csv(file_path, skiprows=range(1, 1500), nrows=500)\n",
        "        data['aT (m/s^2)'] = scaler.transform(data['aT (m/s^2)'].values.reshape(-1, 1))\n",
        "\n",
        "        cfg = tsfel.get_features_by_domain()\n",
        "        features = tsfel.time_series_features_extractor(cfg, data['aT (m/s^2)'], verbose=0)\n",
        "\n",
        "        features_list_test.append(features.values.flatten())\n",
        "        labels_test.append(activity)\n",
        "\n",
        "features_array_test = np.array(features_list_test)\n",
        "y_test = np.array(labels_test)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(features_array_test)\n",
        "\n",
        "eval(labels_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ttYjS-g_aJ"
      },
      "source": [
        "The Model performed well but needs a lot of improvement as the accuracy,precision and recall are not high. Even though the model is not predicitng the activities with higher accuracy, its able to predict the activity better than randomly guessing with an accuracy of 16.67% ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKIdm-e1En-K"
      },
      "source": [
        "2) Use the data you collected to predict the activities that you performed. Decide whether to apply preprocessing and featurization, and if so, choose the appropriate methods. How did the model perform? [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLWFyAwoD8bx",
        "outputId": "bda0ef6e-0375-46dd-92c3-35c539087101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy= 0.4166666666666667\n",
            "Precision:  0.47222222222222227\n",
            "Recall:  0.4166666666666667\n",
            "Confusion Matrix:\n",
            "[[1 1 0 0 0 0]\n",
            " [0 1 0 1 0 0]\n",
            " [0 0 1 1 0 0]\n",
            " [0 0 0 0 2 0]\n",
            " [0 0 0 0 2 0]\n",
            " [0 0 0 0 2 0]]\n"
          ]
        }
      ],
      "source": [
        "def load_data(activity_dirs, csv_names):\n",
        "    data = {}\n",
        "    for activity, folder in activity_dirs.items():\n",
        "        data[activity] = [pd.read_csv(f\"{folder}/{csv_name}.csv\") for csv_name in csv_names]\n",
        "    return data\n",
        "\n",
        "def normalize_data(df, column_name):\n",
        "    scaler = StandardScaler()\n",
        "    df[column_name] = scaler.fit_transform(df[[column_name]])\n",
        "    return df, scaler\n",
        "\n",
        "csv_names = ['a', 'p', 'd', 's']\n",
        "data = load_data(activity_dirs_test, csv_names)\n",
        "\n",
        "original_list = [0, 1, 2, 3]\n",
        "list1 = random.sample(original_list, 2)\n",
        "list2 = [num for num in original_list if num not in list1]\n",
        "\n",
        "def process_and_normalize(activity_dirs, csv_names, indices):\n",
        "    features_list = []\n",
        "    labels_list = []\n",
        "    scaler = None\n",
        "\n",
        "    for activity, folder in activity_dirs.items():\n",
        "        for idx in indices:\n",
        "            file_path = os.path.join(folder, f\"{csv_names[idx]}.csv\")\n",
        "            data = pd.read_csv(file_path)\n",
        "\n",
        "            if scaler is None:\n",
        "                data, scaler = normalize_data(data, 'aT (m/s^2)')\n",
        "            else:\n",
        "                data, _ = normalize_data(data, 'aT (m/s^2)')\n",
        "\n",
        "            cfg = tsfel.get_features_by_domain()\n",
        "            features = tsfel.time_series_features_extractor(cfg, data['aT (m/s^2)'], verbose=0)\n",
        "\n",
        "            features_list.append(features.values.flatten())\n",
        "            labels_list.extend([activity] * len(features))\n",
        "\n",
        "    return np.array(features_list), np.array(labels_list), scaler\n",
        "\n",
        "X_train, y_train, scaler = process_and_normalize(activity_dirs_test, csv_names, list1)\n",
        "X_test, y_test, _ = process_and_normalize(activity_dirs_test, csv_names, list2)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "eval(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZAD5VYllQ6X"
      },
      "source": [
        "The results of the model's performance suggest that while the model is  effective, there is room for improvement. Using cross-validation can improve the model performance. Using more data might enhance accuracy and overall performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH164pRpFy3K"
      },
      "source": [
        "3) Use the Few-Shot prompting method using UCI-HAR dataset to predict the activities that you performed. Ensure that both your examples and test query undergo similar preprocessing. How did the model perform? [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V70_44ouD8by",
        "outputId": "9f88500b-64ab-4b30-af82-d9d6401a3eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Few-shot Testing Accuracy:  0.16666666666666666\n"
          ]
        }
      ],
      "source": [
        "def compute_acceleration(df, col_x='accx', col_y='accy', col_z='accz'):\n",
        "    return (df[col_x]**2 + df[col_y]**2 + df[col_z]**2)**0.5\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for _ in range(20):\n",
        "    activity = random.choice(list(activity_dirs_train.keys()))\n",
        "    activity_dir = activity_dirs_train[activity]\n",
        "    csv_file = random.choice(os.listdir(activity_dir))\n",
        "    file_path = os.path.join(activity_dir, csv_file)\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    time_point = random.randint(0, len(df) - 1)\n",
        "    acc = compute_acceleration(df.iloc[time_point])\n",
        "\n",
        "    X_train.append(acc)\n",
        "    y_train.append(activity)\n",
        "\n",
        "X_train = np.array(X_train).reshape(-1, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for activity, activity_dir in activity_dirs_test.items():\n",
        "    for file_name in os.listdir(activity_dir):\n",
        "        file_path = os.path.join(activity_dir, file_name)\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        if 'aT (m/s^2)' in data.columns:\n",
        "            value = data['aT (m/s^2)'].iloc[0]\n",
        "            X_test.append(value)\n",
        "            y_test.append(activity)\n",
        "\n",
        "X_test_df = pd.DataFrame(X_test, columns=['aT (m/s^2)'])\n",
        "y_test_df = pd.DataFrame(y_test, columns=['Activity'])\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test_df[['aT (m/s^2)']])\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=['aT (m/s^2)'])\n",
        "\n",
        "combined_df = pd.concat([X_test_scaled_df, y_test_df], axis=1)\n",
        "shuffled_df = shuffle(combined_df, random_state=42)\n",
        "\n",
        "X_test = shuffled_df[['aT (m/s^2)']]\n",
        "y_test = shuffled_df[['Activity']]\n",
        "\n",
        "feature_label_dict = {tuple(row): label for row, label in zip(X_train, y_train)}\n",
        "\n",
        "def classify_sample(sample, feature_label_dict):\n",
        "    features = \", \".join([f\"Feature_{i+1}: {value}\" for i, value in enumerate(sample)])\n",
        "    query = f\"\"\"\n",
        "    * You are a human activities classification model.\n",
        "    * Your task is to analyze the given features and classify them as one of these 6 activities: {', '.join(label_set)}.\n",
        "    * Provide only the activity label.\n",
        "\n",
        "    Examples:\n",
        "    {feature_label_dict}\n",
        "\n",
        "    Features:\n",
        "    {features}\n",
        "    \"\"\"\n",
        "    answer = llm.invoke(query)\n",
        "    return answer.content.strip()\n",
        "\n",
        "def classify_samples(X, feature_label_dict):\n",
        "    predictions = [classify_sample(row, feature_label_dict) for _, row in X.iterrows()]\n",
        "    return pd.Series(predictions)\n",
        "\n",
        "label_set = list(activity_dirs_train.keys())\n",
        "\n",
        "test_predictions = classify_samples(X_test, feature_label_dict)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"Few-shot Testing Accuracy: \",test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptWHab2smczS"
      },
      "source": [
        "This low accuracy suggests that the model struggled to generalize from the few examples provided. Overall, the performance highlights a need for better example selection to achieve more accurate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvK2PStIGK_E"
      },
      "source": [
        "4) Use the Few-Shot prompting method using the data you collected to predict the activities that you performed. Adopt proper processing methods as needed. How did the model perform? [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K3cJeMXeHnxa",
        "outputId": "3b52e2af-6680-4e24-9b1e-1059ee5fd93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Few-shot Testing Accuracy: 0.2667\n"
          ]
        }
      ],
      "source": [
        "activity_dirs_train = {\n",
        "    'LAYING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/LAYING\",\n",
        "    'SITTING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/SITTING\",\n",
        "    'STANDING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/STANDING\",\n",
        "    'WALKING': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING\",\n",
        "    'WALKING_DOWNSTAIRS': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING_DOWNSTAIRS\",\n",
        "    'WALKING_UPSTAIRS': \"/content/drive/MyDrive/ML Assignment1/Combined/Train/WALKING_UPSTAIRS\"\n",
        "}\n",
        "\n",
        "activity_dirs_test = {\n",
        "    'LAYING': \"/content/drive/MyDrive/ACTIVITIES/LAYING\",\n",
        "    'SITTING': \"/content/drive/MyDrive/ACTIVITIES/SITTING\",\n",
        "    'STANDING': \"/content/drive/MyDrive/ACTIVITIES/STANDING\",\n",
        "    'WALKING': \"/content/drive/MyDrive/ACTIVITIES/WALKING\",\n",
        "    'WALKING_DOWNSTAIRS': \"/content/drive/MyDrive/ACTIVITIES/WALKING_DOWNSTAIRS\",\n",
        "    'WALKING_UPSTAIRS': \"/content/drive/MyDrive/ACTIVITIES/WALKING_UPSTAIRS\"\n",
        "}\n",
        "\n",
        "csv_names = ['a.csv', 'p.csv', 'd.csv', 's.csv']\n",
        "\n",
        "def select_random_csv_files(available_files, num_files, seed):\n",
        "    random.seed(seed)\n",
        "    return random.sample(available_files, num_files)\n",
        "\n",
        "def gather_data(activity_dirs, num_samples, chosen_files=None, test_mode=False):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for activity, folder_path in activity_dirs.items():\n",
        "        all_files = [f for f in os.listdir(folder_path) if f in csv_names]\n",
        "\n",
        "        if test_mode:\n",
        "            available_files = list(set(all_files) - set(chosen_files))\n",
        "            # if len(available_files) != 2:\n",
        "            #     raise ValueError(f\"Expected 2 files left for testing in folder {folder_path}. Found {len(available_files)}.\")\n",
        "        else:\n",
        "            available_files = all_files\n",
        "\n",
        "        # if len(available_files) < 2:\n",
        "        #     raise ValueError(f\"Not enough CSV files in folder {folder_path}.\")\n",
        "\n",
        "        if not test_mode:\n",
        "            chosen_files = select_random_csv_files(available_files, 2, seed=2)\n",
        "        else:\n",
        "            chosen_files = available_files\n",
        "\n",
        "        for _ in range(num_samples):\n",
        "            selected_file = random.choice(chosen_files)\n",
        "            file_path = os.path.join(folder_path, selected_file)\n",
        "\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # if 'aT (m/s^2)' not in df.columns:\n",
        "            #     raise ValueError(f\"'aT (m/s^2)' column not found in file {file_path}.\")\n",
        "\n",
        "            # if len(df) == 0:\n",
        "            #     raise ValueError(f\"No data in file {file_path}.\")\n",
        "\n",
        "            time_point = random.randint(0, len(df) - 1)\n",
        "            total_acc = df.iloc[time_point]['aT (m/s^2)']\n",
        "\n",
        "            X.append(total_acc)\n",
        "            y.append(activity)\n",
        "\n",
        "    return np.array(X).reshape(-1, 1), np.array(y), chosen_files\n",
        "\n",
        "X_train, y_train, chosen_files = gather_data(activity_dirs_test, num_samples=10)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test, y_test, _ = gather_data(activity_dirs_test, num_samples=10, chosen_files=chosen_files, test_mode=True)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "feature_label_dict = {tuple(row): label for row, label in zip(X_train, y_train)}\n",
        "\n",
        "model_name = \"llama3-8b\"\n",
        "groq_models = {\n",
        "    \"llama3-70b\": \"llama3-70b-8192\",\n",
        "    \"mixtral\": \"mixtral-8x7b-32768\",\n",
        "    \"gemma-7b\": \"gemma-7b-it\",\n",
        "    \"llama3.1-70b\": \"llama-3.1-70b-versatile\",\n",
        "    \"llama3-8b\": \"llama3-8b-8192\",\n",
        "    \"llama3.1-8b\": \"llama-3.1-8b-instant\",\n",
        "    \"gemma-9b\": \"gemma2-9b-it\"\n",
        "}\n",
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/key.json') as config_file:\n",
        "    config = json.load(config_file)\n",
        "    Groq_Token = config['groq_token']\n",
        "\n",
        "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
        "\n",
        "def classify_sample(sample, feature_label_dict):\n",
        "    features = \", \".join([f\"Feature_{i+1}: {value}\" for i, value in enumerate(sample)])\n",
        "    query = f\"\"\"\n",
        "    * You are a human activities classification model.\n",
        "    * Your task is to analyze the given features and classify them as one of these 6 activities: {', '.join(label_set)}.\n",
        "    * Provide only the activity label.\n",
        "\n",
        "    Examples:\n",
        "    {feature_label_dict}\n",
        "\n",
        "    Features:\n",
        "    {features}\n",
        "    \"\"\"\n",
        "    answer = llm.invoke(query)\n",
        "    return answer.content.strip()\n",
        "\n",
        "# Function to classify all samples\n",
        "def classify_samples(X, feature_label_dict):\n",
        "    predictions = [classify_sample(row, feature_label_dict) for row in X]\n",
        "    return pd.Series(predictions)\n",
        "\n",
        "\n",
        "test_predictions = classify_samples(X_test, feature_label_dict)\n",
        "\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f\"Few-shot Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REd67VLHYHXI"
      },
      "source": [
        "The Model is not good as the model is only able to predict 25% of the timepoints correctly. Further tuning, additional examples could potentially improve performance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}